{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT THE REQUIRED LIBRARIES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold  ... relevant_yn_gold  \\\n",
       "0                     1.0000            NaN  ...              NaN   \n",
       "1                     1.0000            NaN  ...              NaN   \n",
       "2                     0.6629            NaN  ...              NaN   \n",
       "3                     0.7039            NaN  ...              NaN   \n",
       "4                     1.0000            NaN  ...              NaN   \n",
       "\n",
       "  retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0             5             NaN                 NaN   \n",
       "1            26             NaN                 NaN   \n",
       "2            27             NaN                 NaN   \n",
       "3           138             NaN                 NaN   \n",
       "4           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN   \n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Sentiment.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape ## defines the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Number of Positive and Negative Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count :  2236\n",
      "Negative count :  8493\n",
      "Total positive and negative count :  10729\n"
     ]
    }
   ],
   "source": [
    "p_count = 0\n",
    "n_count = 0\n",
    "for i in df[\"sentiment\"]:\n",
    "    if i == \"Positive\":\n",
    "        p_count += 1\n",
    "    elif i == \"Negative\":\n",
    "        n_count += 1\n",
    "print(\"Positive count : \", p_count)\n",
    "print(\"Negative count : \", n_count)\n",
    "print(\"Total positive and negative count : \", p_count + n_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"sentiment\"] != \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "1  Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
       "3  Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
       "4  Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...\n",
       "5  Positive  RT @GregAbbott_TX: @TedCruz: \"On my first day ...\n",
       "6  Negative  RT @warriorwoman91: I liked her and was happy ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df[[\"sentiment\", \"text\"]]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-ff996dc36479>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new['text'] = df_new['text'].apply(lambda cw : remove_tags(cw))\n"
     ]
    }
   ],
   "source": [
    "def remove_tags(string):\n",
    "    removelist = \"\"\n",
    "    result = re.sub('RT','',string) # Remove RT from text         \n",
    "    result = result.lower()\n",
    "    return result\n",
    "df_new['text'] = df_new['text'].apply(lambda cw : remove_tags(cw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-452c90741b69>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new['text'] = df_new['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n"
     ]
    }
   ],
   "source": [
    "# Removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_new['text'] = df_new['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-700e9e2d8051>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new['text'] = df_new.text.apply(lemmatize_text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13132</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@rwsurfergirl: jeb bush reminds elevator music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11596</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@supermanhotmale: dear #gop, nobody like abort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@rwsurfergirl: anyone else want punch chris wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Negative</td>\n",
       "      <td>seriously thinking voting donald trump ignoran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13451</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@ericstonestreet: trump cam hands. #gopdebates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>Positive</td>\n",
       "      <td>#gopdebate showed politician great liars. smoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>Positive</td>\n",
       "      <td>@govmikehuckabee: pledge oppose amnesty &amp;amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12633</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@rwsurfergirl #gopdebates biased trump others,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>Positive</td>\n",
       "      <td>@megynkelly well done! #gopdebate suppose adva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>Negative</td>\n",
       "      <td>funny twitter last night #gopdebate fucking sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7154</th>\n",
       "      <td>Negative</td>\n",
       "      <td>.@cnbc- u bother mention misrepresentation #fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10772</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@rwsurfergirl: candidate attack @realdonaldtru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>Negative</td>\n",
       "      <td>wanted see grown men throw hissy fits, would w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@gamma_ray239: disappointed @foxnews, treated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@bettyfckinwhite: donald trump biff back futur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "13132  Negative  @rwsurfergirl: jeb bush reminds elevator music...\n",
       "11596  Negative  @supermanhotmale: dear #gop, nobody like abort...\n",
       "11291  Negative  @rwsurfergirl: anyone else want punch chris wa...\n",
       "4995   Negative  seriously thinking voting donald trump ignoran...\n",
       "13451  Negative    @ericstonestreet: trump cam hands. #gopdebates \n",
       "4866   Positive  #gopdebate showed politician great liars. smoo...\n",
       "2158   Positive  @govmikehuckabee: pledge oppose amnesty &amp; ...\n",
       "12633  Negative  @rwsurfergirl #gopdebates biased trump others,...\n",
       "2513   Positive  @megynkelly well done! #gopdebate suppose adva...\n",
       "2850   Negative  funny twitter last night #gopdebate fucking sc...\n",
       "7154   Negative  .@cnbc- u bother mention misrepresentation #fa...\n",
       "10772  Negative  @rwsurfergirl: candidate attack @realdonaldtru...\n",
       "7955   Negative  wanted see grown men throw hissy fits, would w...\n",
       "6045   Negative  @gamma_ray239: disappointed @foxnews, treated ...\n",
       "8399   Negative  @bettyfckinwhite: donald trump biff back futur..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizing text\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "df_new['text'] = df_new.text.apply(lemmatize_text)\n",
    "df_new.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Labels\n",
    "reviews = df_new[\"text\"].values\n",
    "labels = df_new[\"sentiment\"].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Sentences\n",
    "vocab_size = 3000 \n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 200 \n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 100)          300000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387,601\n",
      "Trainable params: 387,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "227/227 [==============================] - 36s 145ms/step - loss: 0.4156 - accuracy: 0.8272 - val_loss: 0.4105 - val_accuracy: 0.8161\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 32s 142ms/step - loss: 0.2700 - accuracy: 0.8843 - val_loss: 0.4110 - val_accuracy: 0.8360\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 33s 146ms/step - loss: 0.2174 - accuracy: 0.9094 - val_loss: 0.4654 - val_accuracy: 0.8323\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 33s 145ms/step - loss: 0.1763 - accuracy: 0.9264 - val_loss: 0.6430 - val_accuracy: 0.8174\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 33s 146ms/step - loss: 0.1437 - accuracy: 0.9420 - val_loss: 0.7141 - val_accuracy: 0.8037\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history = model.fit(train_padded, train_labels, \n",
    "                    epochs = num_epochs, verbose = 1, \n",
    "                    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediction on test set :  0.8237048080506896\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_padded)\n",
    "pred_labels = []\n",
    "\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "print(\"Accuracy of prediction on test set : \", accuracy_score(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking sentiments for the given sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is a great leader.\n",
      "Predicted sentiment :  Positive\n",
      "He is a terrible leader.\n",
      "Predicted sentiment :  Negative\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"He is a great leader.\", \n",
    "            \"He is a terrible leader.\"]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "\n",
    "padded = pad_sequences(sequences, padding='post', maxlen=max_length)\n",
    "prediction = model.predict(padded)\n",
    "pred_labels = []\n",
    "\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "        \n",
    "for i in range(len(sentence)):\n",
    "    print(sentence[i])\n",
    "    if pred_labels[i] == 1:\n",
    "        s = 'Positive'\n",
    "    else:\n",
    "        s = 'Negative'\n",
    "    print(\"Predicted sentiment : \",s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
